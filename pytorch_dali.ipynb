{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-dali.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoneken1/colab_pytorch_sample/blob/master/pytorch_dali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94diSx4HWpdT",
        "colab_type": "text"
      },
      "source": [
        "# DALIインストール\n",
        "Google Colaboratoryの環境に合わせてCuda10版を入れる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qbn0oHlUzFh",
        "colab_type": "code",
        "outputId": "da93450b-a199-4f50-a5ce-e890655854d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/cuda/10.0 nvidia-dali"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://developer.download.nvidia.com/compute/redist/cuda/10.0\n",
            "Collecting nvidia-dali\n",
            "\u001b[?25l  Downloading https://developer.download.nvidia.com/compute/redist/cuda/10.0/nvidia-dali/nvidia_dali-0.13.0-853141-cp36-cp36m-manylinux1_x86_64.whl (37.0MB)\n",
            "\u001b[K     |████████████████████████████████| 37.0MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nvidia-dali) (0.16.0)\n",
            "Installing collected packages: nvidia-dali\n",
            "Successfully installed nvidia-dali-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeG6zcmKXD0k",
        "colab_type": "text"
      },
      "source": [
        "# MS-COCOのアノテーションデータの準備\n",
        "ms-cocoを使って試すために、アノテーションデータを落として解凍する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woHbyhTzU-gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /content/\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip '/content/annotations_trainval2017.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM9VHqM-eQyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /content/\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip '/content/val2017.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs-baR3ggt4l",
        "colab_type": "text"
      },
      "source": [
        "# PyTorchのDataLoaderを使う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l694ve87s9KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "DATA_LOAD_TIME = 0.01\n",
        "LEARNING_TIME = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-41PUOIxWYDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i8sFXJ6XmJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CocoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataType='val2017'):\n",
        "\n",
        "        annFile='/content/annotations/instances_{}.json'.format(dataType)\n",
        "        self.coco=COCO(annFile)\n",
        "        self.ids = list(self.coco.imgToAnns.keys())\n",
        "        self.imgs = self.coco.loadImgs(self.ids)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        img_path = os.path.join('/content/val2017', self.imgs[idx]['file_name'])\n",
        "        time.sleep(DATA_LOAD_TIME) #for simulation of very slow file IO\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (512,512))\n",
        "        return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQw-tunbFEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def collate_fn(batch):\n",
        "    imgs = [x for x in batch]\n",
        "    return imgs\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kXZV-o3ZkW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64b43ee2-3b61-40ac-8f13-d7448c5a218e"
      },
      "source": [
        "coco_dataset = CocoDataset()\n",
        "coco_dataloader = DataLoader(coco_dataset, num_workers=8, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.41s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDQHLqsCZocE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5af6e509-ecb1-4142-fa3d-2e3ff30fae32"
      },
      "source": [
        "data_iter = iter(coco_dataloader)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "  images = next(data_iter)\n",
        "  time.sleep(LEARNING_TIME) #for simulation of DeepLearning\n",
        "end = time.time()\n",
        "\n",
        "print('total_time : %s' % ( str(end-start) ))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_time : 11.102628707885742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPUGZN69g8T5",
        "colab_type": "text"
      },
      "source": [
        "# DALIのサンプルに従う場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkJjlIpxiqzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import types\n",
        "import collections\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from nvidia.dali.pipeline import Pipeline\n",
        "import nvidia.dali.ops as ops            \n",
        "import nvidia.dali.types as types\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVDVB541afaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExternalInputIterator(object):\n",
        "    def __init__(self, batch_size, dataType='val2017'):\n",
        "\n",
        "        annFile='/content/annotations/instances_{}.json'.format(dataType)\n",
        "        self.coco=COCO(annFile)\n",
        "        self.ids = list(self.coco.imgToAnns.keys())\n",
        "        self.imgs = self.coco.loadImgs(self.ids)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.data_set_len = len(self.imgs) \n",
        "        self.n = len(self.imgs)\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.i = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        batch = []\n",
        "\n",
        "        if self.i >= self.n:\n",
        "            raise StopIteration\n",
        "\n",
        "        for _ in range(self.batch_size):\n",
        "            img_path = os.path.join('/content/val2017', self.imgs[self.i]['file_name'])\n",
        "            f = open(img_path, 'rb')\n",
        "            time.sleep(DATA_LOAD_TIME) #for simulation of very slow file IO\n",
        "            batch.append(np.frombuffer(f.read(), dtype = np.uint8))\n",
        "            self.i = (self.i + 1) % self.n\n",
        "        return batch\n",
        "\n",
        "    @property\n",
        "    def size(self,):\n",
        "        return self.data_set_len\n",
        "\n",
        "    next = __next__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2YcxDW0bxeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExternalSourcePipeline(Pipeline):\n",
        "    def __init__(self, batch_size, num_threads, device_id, external_data):\n",
        "        super(ExternalSourcePipeline, self).__init__(batch_size,\n",
        "                                      num_threads,\n",
        "                                      device_id,\n",
        "                                      seed=12)\n",
        "        self.input = ops.ExternalSource()\n",
        "        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n",
        "        self.res = ops.Resize(device=\"gpu\", resize_x=512, resize_y=512)\n",
        "        self.external_data = external_data\n",
        "        self.iterator = iter(self.external_data)\n",
        "\n",
        "    def define_graph(self):\n",
        "        self.jpegs = self.input()\n",
        "        images = self.decode(self.jpegs)\n",
        "        images = self.res(images)\n",
        "        return images\n",
        "\n",
        "    def iter_setup(self):\n",
        "        try:\n",
        "            images = self.iterator.next()\n",
        "            self.feed_input(self.jpegs, images)\n",
        "        except StopIteration:\n",
        "            self.iterator = iter(self.external_data)\n",
        "            raise StopIteration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z2qQstdioSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "af139751-2406-43c1-c431-ce7470973433"
      },
      "source": [
        "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
        "\n",
        "eii = ExternalInputIterator(batch_size=BATCH_SIZE)\n",
        "pipe = ExternalSourcePipeline(batch_size=BATCH_SIZE, num_threads=2, device_id = 0,\n",
        "                              external_data = eii)\n",
        "pii = DALIGenericIterator(pipe, ['image'], size=100*BATCH_SIZE, last_batch_padded=True, fill_last_batch=False)\n",
        "\n",
        "start = time.time()\n",
        "for i, data in enumerate(pii):\n",
        "    images = data[0][\"image\"]\n",
        "    time.sleep(LEARNING_TIME) #for simulation of DeepLearning\n",
        "end = time.time()\n",
        "\n",
        "print('total_time : %s' % ( str(end-start) ))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.09s)\n",
            "creating index...\n",
            "index created!\n",
            "total_time : 14.16463017463684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw8JXEkqnFB-",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch DataLoader × DALI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iglBI_h6jMqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CocoDatasetForDALI(Dataset):\n",
        "\n",
        "    def __init__(self, dataType='val2017'):\n",
        "\n",
        "        annFile='/content/annotations/instances_{}.json'.format(dataType)\n",
        "        self.coco=COCO(annFile)\n",
        "        self.ids = list(self.coco.imgToAnns.keys())\n",
        "        self.imgs = self.coco.loadImgs(self.ids)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        img_path = os.path.join('/content/val2017', self.imgs[idx]['file_name'])\n",
        "        f = open(img_path, 'rb')\n",
        "        time.sleep(DATA_LOAD_TIME) #for simulation of very slow file IO\n",
        "        img = np.frombuffer(f.read(), dtype = np.uint8)\n",
        "        return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0l9QyLqnB3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExternalSourcePipelineForPytorch(Pipeline):\n",
        "    def __init__(self, batch_size, num_threads, device_id, external_data):\n",
        "        super(ExternalSourcePipelineForPytorch, self).__init__(batch_size,\n",
        "                                      num_threads,\n",
        "                                      device_id,\n",
        "                                      seed=12)\n",
        "        self.input = ops.ExternalSource()\n",
        "        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n",
        "        self.res = ops.Resize(device=\"gpu\", resize_x=512, resize_y=512)\n",
        "        self.external_data = external_data\n",
        "        self.iterator = iter(self.external_data)\n",
        "\n",
        "    def define_graph(self):\n",
        "        self.jpegs = self.input()\n",
        "        images = self.decode(self.jpegs)\n",
        "        images = self.res(images)\n",
        "        return images\n",
        "\n",
        "    def iter_setup(self):\n",
        "        try:\n",
        "            images = next(self.iterator)\n",
        "            self.feed_input(self.jpegs, images)\n",
        "        except StopIteration:\n",
        "            self.iterator = iter(self.external_data)\n",
        "            raise StopIteration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47LTqghmzwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "793055eb-37f2-4938-ad29-c65aa153ceda"
      },
      "source": [
        "coco_dataset_for_dali = CocoDatasetForDALI()\n",
        "coco_dataloader_for_dali = DataLoader(coco_dataset_for_dali, num_workers=8, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "pipe = ExternalSourcePipelineForPytorch(batch_size=BATCH_SIZE, num_threads=2, device_id = 0,\n",
        "                              external_data = coco_dataloader_for_dali)\n",
        "pii = DALIGenericIterator(pipe, ['image'], size=100*BATCH_SIZE, last_batch_padded=True, fill_last_batch=False)\n",
        "\n",
        "start = time.time()\n",
        "for i, data in enumerate(pii):\n",
        "    images = data[0][\"image\"]\n",
        "    time.sleep(LEARNING_TIME) #for simulation of DeepLearning\n",
        "end = time.time()\n",
        "\n",
        "print('total_time : %s' % ( str(end-start) ))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.04s)\n",
            "creating index...\n",
            "index created!\n",
            "total_time : 10.300386428833008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oxEwbrRo4_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdrL_Gqonl5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}